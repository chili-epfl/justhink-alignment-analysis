{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "# from spacy.matcher import Matcher\n",
    "# from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "from read_utils import read_tables, read_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /home/utku/.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/utku/.local/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.17.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (45.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs.\n",
    "data_dir = pl.Path('../data')\n",
    "output_dir = pl.Path('../outputs')\n",
    "interm_dir = output_dir.joinpath('intermediate')\n",
    "corpus_dir = interm_dir.joinpath('corpus')\n",
    "network_file = data_dir.joinpath('metadata/network.json')\n",
    "\n",
    "# # Outputs.\n",
    "# output_dir = pl.Path('../outputs')\n",
    "# intermediate_dir = output_dir.joinpath('intermediate')\n",
    "annot_corpus_dir = interm_dir.joinpath('annotated_corpus')\n",
    "# combined_dir = intermediate_dir.joinpath('logs_with_transcripts')\n",
    "\n",
    "for d in [annot_corpus_dir]:\n",
    "    if not d.exists():\n",
    "        d.mkdir()\n",
    "        print('Created {}'.format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus tables (logs with transcripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading transcript files from ../outputs/intermediate/corpus.\n",
      "transcript 10 files found.\n",
      "File justhink19_corpus_07 belongs to team  7\n",
      "File justhink19_corpus_08 belongs to team  8\n",
      "File justhink19_corpus_09 belongs to team  9\n",
      "File justhink19_corpus_10 belongs to team 10\n",
      "File justhink19_corpus_11 belongs to team 11\n",
      "File justhink19_corpus_17 belongs to team 17\n",
      "File justhink19_corpus_18 belongs to team 18\n",
      "File justhink19_corpus_20 belongs to team 20\n",
      "File justhink19_corpus_28 belongs to team 28\n",
      "File justhink19_corpus_47 belongs to team 47\n",
      "Transcript of  7 has 1059 utterances\n",
      "Transcript of  8 has  932 utterances\n",
      "Transcript of  9 has 1076 utterances\n",
      "Transcript of 10 has  769 utterances\n",
      "Transcript of 11 has  910 utterances\n",
      "Transcript of 17 has  451 utterances\n",
      "Transcript of 18 has  506 utterances\n",
      "Transcript of 20 has  653 utterances\n",
      "Transcript of 28 has  490 utterances\n",
      "Transcript of 47 has  642 utterances\n"
     ]
    }
   ],
   "source": [
    "corpus_dfs = read_tables(corpus_dir, form='transcript')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the background network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network read from : 10 nodes, 20 edges\n"
     ]
    }
   ],
   "source": [
    "network = read_network(network_file)\n",
    "print('Network read from {}: {} nodes, {} edges'.format(\n",
    "    network, network.number_of_nodes(), network.number_of_edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parsers and rulers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define intent keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADD {'add', 'put', 'build', 'connect', 'go', 'do'}\n",
      "REMOVE {'cut', 'remove', 'rub', 'away', 'delete', 'erase'}\n"
     ]
    }
   ],
   "source": [
    "intent_keywords = {\n",
    "    'ADD': {\n",
    "        'add', # \"adding zurich to bern .\"\n",
    "        'do', \n",
    "        'go',\n",
    "        'put',  # \"putting that one there\"\n",
    "        'connect',\n",
    "        'build', # \"i'll build mount luzern to zermatt\"\n",
    "    },\n",
    "    'REMOVE': {\n",
    "        'remove',\n",
    "        \"delete\", #\"okay so delete that .\"\n",
    "        'erase', \n",
    "        'cut', # 'yeah then cut out mount basel to mount interlaken .'\n",
    "        'away', # 'take away',\n",
    "        'rub', # 'rub that out', #as in \"it's 3 francs rub that out\" ; \"no wait let me rub that out again .\" ; \"oh then rub that out\"\n",
    "    },\n",
    "}\n",
    "\n",
    "for k, words in intent_keywords.items():\n",
    "    print(k, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to recognise intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ADD(9, None)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">to mount \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    davos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NODE</span>\n",
       "</mark>\n",
       " .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_ruler(network, intent_keywords):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "    ruler = EntityRuler(nlp)\n",
    "\n",
    "    node_ids = list()\n",
    "    node_patterns = list()\n",
    "    for u, d in network.nodes(data=True):\n",
    "        word = d['label'].split()[-1]\n",
    "        identifier = str(u)\n",
    "        pattern = {'id': identifier, 'label': 'NODE', \"pattern\": [\n",
    "            {'LOWER': word.lower()}]}\n",
    "        node_patterns.append(pattern)\n",
    "        node_ids.append(identifier)\n",
    "\n",
    "    intent_ids = list()\n",
    "    intent_patterns = list()\n",
    "    for label, words in intent_keywords.items():\n",
    "        for word in words:\n",
    "            identifier = str(label)  # [0]\n",
    "            pattern = {'id': identifier, 'label': label, \"pattern\": [\n",
    "                {'LOWER': word.lower()}]}\n",
    "            intent_patterns.append(pattern)\n",
    "            intent_ids.append(identifier)\n",
    "\n",
    "    demonstrative_patterns = list()\n",
    "    for word in ['it', 'that']:\n",
    "        identifier = 'DEM'\n",
    "        pattern = {'id': identifier, 'label': 'DEM', \"pattern\": [\n",
    "            {'LOWER': word.lower()}]}  # str(identifier)} #  word} #\n",
    "        node_patterns.append(pattern)\n",
    "\n",
    "    patterns = [\n",
    "        *node_patterns,\n",
    "        *intent_patterns,\n",
    "        *demonstrative_patterns,\n",
    "    ]\n",
    "    ruler.add_patterns(patterns)\n",
    "    nlp.add_pipe(ruler)\n",
    "\n",
    "    return nlp, node_ids, intent_ids\n",
    "\n",
    "\n",
    "def get_node_ids(text, doc):\n",
    "    node_ids = [int(ent.ent_id_) for ent in doc.ents if ent.label_ == 'NODE']\n",
    "    return node_ids\n",
    "\n",
    "\n",
    "class Edge(object):\n",
    "    def __init__(self, u, v):\n",
    "        self.u = int(u) if u is not None else u\n",
    "        self.v = int(v) if v is not None else v\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Edge):\n",
    "            return (self.u == other.u and self.v == other.v) \\\n",
    "                or (self.u == other.v and self.v == other.u)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.u, self.v))\n",
    "\n",
    "    def __str__(self):\n",
    "        return '{}, {}'.format(self.u, self.v)\n",
    "\n",
    "\n",
    "class Action(object):\n",
    "    def __init__(self, name, content):\n",
    "        self.name = name\n",
    "        self.content = content\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Action):\n",
    "            return self.name == other.name \\\n",
    "                and self.content == other.content\n",
    "\n",
    "    def partial_equals(self, other):\n",
    "        assert isinstance(self.content, Edge) and isinstance(\n",
    "            other.content, Edge), 'not implemented'\n",
    "        if self.name != other.name:\n",
    "            return False\n",
    "        u, v = self.content.u, self.content.v\n",
    "        ou, ov = other.content.u, other.content.v\n",
    "        if v is None or ov is None:\n",
    "            return u == ou or u == ov or v == ou or v == ov\n",
    "        else:\n",
    "            return (u == ou or u == ov) and (v == ou or v == ov)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.name, self.content))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({})'.format(self.name, self.content)\n",
    "\n",
    "\n",
    "class AddAction(Action):\n",
    "    def __init__(self, edge):\n",
    "        self.name = 'ADD'\n",
    "        self.edge = edge\n",
    "        super().__init__(self.name, self.edge)\n",
    "\n",
    "\n",
    "class RemoveAction(Action):\n",
    "    def __init__(self, edge):\n",
    "        self.name = 'REMOVE'\n",
    "        self.edge = edge\n",
    "        super().__init__(self.name, self.edge)\n",
    "\n",
    "\n",
    "class CoreAct(object):\n",
    "    def __init__(self, name, content, agent='X'):\n",
    "        self.name = name\n",
    "        self.content = content\n",
    "        self.agent = agent\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}_{}({})'.format(self.name, self.agent, self.content)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.name, self.content, self.agent))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, CoreAct):\n",
    "            return self.name == other.name \\\n",
    "                and self.content == other.content \\\n",
    "                and self.agent == other.agent\n",
    "\n",
    "\n",
    "class SuggestAct(CoreAct):\n",
    "    def __init__(self, action, agent='X'):\n",
    "        self.name = 'SUGGEST'\n",
    "        self.action = action\n",
    "        self.agent = agent\n",
    "        super().__init__('{}'.format(self.name), action, agent)\n",
    "\n",
    "\n",
    "class FreeAct(CoreAct):\n",
    "    def __init__(self, action, agent='X'):\n",
    "        self.name = 'FREE'\n",
    "        self.action = action\n",
    "        self.agent = agent\n",
    "        super().__init__('{}'.format(self.name), action, agent)\n",
    "\n",
    "\n",
    "class PhysicalAct(CoreAct):\n",
    "    def __init__(self, action, agent='X'):\n",
    "        self.name = 'DO'\n",
    "        self.action = action\n",
    "        self.agent = agent\n",
    "        super().__init__('{}'.format(self.name), action, agent)\n",
    "\n",
    "\n",
    "class AcceptAct(CoreAct):\n",
    "    def __init__(self, suggest_act, agent='X'):\n",
    "        self.name = 'ACCEPT'\n",
    "        self.suggest_act = suggest_act\n",
    "        super().__init__('{}'.format(self.name), suggest_act, agent)\n",
    "\n",
    "\n",
    "class RejectAct(CoreAct):\n",
    "    def __init__(self, suggest_act, agent='X'):\n",
    "        self.name = 'REJECT'\n",
    "        self.suggest_act = suggest_act\n",
    "        super().__init__('{}'.format(self.name), suggest_act, agent)\n",
    "\n",
    "\n",
    "def recognize_intents(text, doc, node_ids, intent_ids, default_intent_id='ADD'):\n",
    "    # # Intents.\n",
    "    intents = list()\n",
    "    intent = [None, [None, None]]\n",
    "    is_inferring = False\n",
    "    for ent in doc.ents:\n",
    "        ent_id = ent.ent_id_\n",
    "\n",
    "        if ent_id in intent_ids:\n",
    "            if intent[0] is None:\n",
    "                intent[0] = ent_id\n",
    "            else:\n",
    "                intent = [ent_id, [None, None]]\n",
    "\n",
    "        elif ent_id in node_ids:\n",
    "            if intent[1][0] is None:\n",
    "                intent[1][0] = ent_id\n",
    "            elif intent[1][1] is None:\n",
    "                if ent_id != intent[1][0]:\n",
    "                    intent[1][1] = ent_id\n",
    "                # Start a new intent if has a verb. Default to add or the previous\n",
    "                if intent[0] is None:\n",
    "                    if len(intents) > 0:\n",
    "                        # intent[0] = intents[-1][0]\n",
    "                        intent[0] = intents[-1].name\n",
    "                    else:\n",
    "                        intent[0] = default_intent_id\n",
    "\n",
    "                action = make_edit_action(intent[0], intent[1])\n",
    "                # intents.append(intent)\n",
    "                if action is not None:\n",
    "                    intents.append(action)\n",
    "                intent = [None, [None, None]]\n",
    "\n",
    "    if intent[1][0] is not None:\n",
    "        if intent[0] is None:  # assume adds if otherwise detected\n",
    "            intent[0] = 'ADD'\n",
    "        action = make_edit_action(intent[0], intent[1])\n",
    "        if action is not None:\n",
    "            intents.append(action)\n",
    "\n",
    "    return intents\n",
    "\n",
    "\n",
    "def make_edit_action(action_name, action_edge):\n",
    "    action = None\n",
    "    u, v = action_edge\n",
    "    edge = Edge(u, v)\n",
    "    if action_name == 'ADD':\n",
    "        action = AddAction(edge)\n",
    "    elif action_name == 'REMOVE':\n",
    "        action = RemoveAction(edge)\n",
    "    return action\n",
    "\n",
    "\n",
    "# Try\n",
    "text = \"go from basel to zurich and then from zurich to saint gallen .\"\n",
    "# text = \"then rub that out and then go , interlaken to mount bern .\"\n",
    "text = \"okay rub it out and go bern to interlaken .\"\n",
    "text = 'is that how much that ?'\n",
    "text = \"how do i get off this screen ?\"\n",
    "text = \"go from basel to zurich and then from zurich to saint gallen .\"\n",
    "text = 'to mount davos .'\n",
    "# text = \"then rub that out and then go , interlaken .\"\n",
    "nlp, node_ids, intent_ids = prepare_ruler(network, intent_keywords)\n",
    "doc = nlp(text)\n",
    "\n",
    "intents = recognize_intents(text, doc, node_ids, intent_ids)\n",
    "# print(intents)\n",
    "display(intents)\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser for edge objects in the extended transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_edge_object(obj, names=False):\n",
    "    ''''Zurich-Gallen (2-8)' to [2, 8]'''\n",
    "    if names: # Parse for names.\n",
    "        (u, v) = obj.split()[0].split('-') \n",
    "    else: # Parse for node indices.\n",
    "        (u, v) = obj.split()[1].strip('(').strip(')').split('-')\n",
    "        u = int(u)\n",
    "        v = int(v)\n",
    "    return [u, v]\n",
    "\n",
    "obj = 'Zurich-Gallen (2-8)'\n",
    "parse_edge_object(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_svo(sbj, verb, obj, nlp, node_ids, intent_ids):\n",
    "    '''recognise intents, make a suggest act or an edit act'''\n",
    "    # Find node list and intent list.\n",
    "    if verb == 'says' and sbj in ['A', 'B']:\n",
    "        text = obj\n",
    "        doc = nlp(text)\n",
    "        node_list = get_node_ids(text, doc)\n",
    "        intent_list = recognize_intents(text, doc, node_ids, intent_ids)\n",
    "        if intent_list is None:\n",
    "            intent_list = []\n",
    "    else:\n",
    "        node_list = []\n",
    "        intent_list = []\n",
    "        \n",
    "    # Find act list.\n",
    "    act_list = list()\n",
    "    for intent in intent_list:\n",
    "        act = SuggestAct(intent, agent=sbj)\n",
    "        act_list.append(act)\n",
    "        # if intent[0] is not None:\n",
    "        #     act = ['SUGGEST', sbj, intent]\n",
    "        #     act_list.append(act)\n",
    "\n",
    "    if verb == 'adds':\n",
    "        act_verb = 'ADD'\n",
    "    elif verb == 'removes':\n",
    "        act_verb = 'REMOVE'\n",
    "    else:\n",
    "        act_verb = None\n",
    "    if act_verb is not None:\n",
    "        action = make_edit_action(act_verb, parse_edge_object(obj))\n",
    "        act = PhysicalAct(action, sbj)\n",
    "        act_list.append(act)\n",
    "    \n",
    "    return node_list, intent_list, act_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e3945c7ec191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mteam_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m \u001b[0;31m#8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteam_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprocess_intents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintent_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-e3945c7ec191>\u001b[0m in \u001b[0;36mprocess_intents\u001b[0;34m(df, network, intent_keywords, inplace)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mact_lists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msbj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mverb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'"
     ]
    }
   ],
   "source": [
    "def process_intents(df, network, intent_keywords, inplace=True):\n",
    "    nlp, node_ids, intent_ids = prepare_ruler(network, intent_keywords)\n",
    "\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "    node_lists = list()\n",
    "    intent_lists = list()\n",
    "    act_lists = list()\n",
    "    for i, row in df.iterrows():\n",
    "        sbj = row['subject']\n",
    "        verb = row['verb']\n",
    "        obj = row['object']\n",
    "\n",
    "        node_list, intent_list, act_list = process_svo(\n",
    "            sbj, verb, obj, nlp, node_ids, intent_ids)\n",
    "\n",
    "        node_lists.append(node_list)\n",
    "        intent_lists.append(intent_list)\n",
    "        act_lists.append(act_list)\n",
    "\n",
    "    df['nodes'] = node_lists\n",
    "    df['intents'] = intent_lists\n",
    "    df['acts'] = act_lists\n",
    "\n",
    "    return df\n",
    "\n",
    "# Try:\n",
    "team_no = 28 #8\n",
    "df = corpus_dfs[team_no]\n",
    "process_intents(df, network, intent_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_suggests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_suggests(df, inplace=True, verbose=False):\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    pending_suggest_actlist = list()\n",
    "    pending_suggest_acts = list() #set()\n",
    "    turn_no = 1\n",
    "    for i, row in df.iterrows():\n",
    "        #pending_suggest_acts = set(pending_suggest_acts)\n",
    "        pending_suggest_acts = list(pending_suggest_acts)\n",
    "        act_list = row['acts']\n",
    "        current_turn_no = row['turn_no']\n",
    "\n",
    "        # flush at every turn change\n",
    "        if current_turn_no != -1 and current_turn_no == turn_no + 1:\n",
    "            if verbose:\n",
    "                print('Cleared at {} at row {}'.format(current_turn_index, i))\n",
    "            pending_suggest_acts = list()\n",
    "            turn_no = current_turn_no\n",
    "\n",
    "\n",
    "        suggest_acts = [act for act in act_list if isinstance(act, SuggestAct)]\n",
    "        edit_acts = [act for act in act_list if isinstance(act, PhysicalAct)]\n",
    "        assert len(edit_acts) <= 1, 'more than one edit act? at {}'.format(row)\n",
    "\n",
    "        pending_suggest_acts = pending_suggest_acts + suggest_acts\n",
    "\n",
    "        if len(edit_acts) > 0:\n",
    "            edit_act = edit_acts[0]\n",
    "\n",
    "            if verbose and len(pending_suggest_acts) > 0:\n",
    "                print()\n",
    "                print('Matching {} to {}'.format(\n",
    "                    pending_suggest_acts, edit_acts))\n",
    "\n",
    "            # check with its only item in this trivial case\n",
    "            # get suggests by the other speaker.\n",
    "            others_acts = [\n",
    "                a for a in pending_suggest_acts if a.agent != row['subject']]\n",
    "            if len(others_acts) > 0:\n",
    "                new_act = None\n",
    "\n",
    "                for suggest_act in others_acts:\n",
    "                    if suggest_act.action.partial_equals(edit_act.action):\n",
    "                        new_act = AcceptAct(suggest_act, agent=edit_act.agent)\n",
    "                        if verbose:\n",
    "                            print('Matched {} to {}'.format(\n",
    "                                edit_act, suggest_act))\n",
    "\n",
    "                suggest_act = others_acts[-1]\n",
    "                if new_act is None:\n",
    "                    new_act = RejectAct(suggest_act, agent=edit_acts[0].agent)\n",
    "                    if verbose:\n",
    "                        print('No match {}: Create {}'.format(\n",
    "                            suggest_act, new_act))\n",
    "\n",
    "                if new_act is not None:\n",
    "                    # remove all that match suggest_act.\n",
    "                    l = list(pending_suggest_acts)\n",
    "                    for s in pending_suggest_acts:\n",
    "                        if s.action.partial_equals(suggest_act.action):\n",
    "                            l.remove(s)\n",
    "                    pending_suggest_acts = l\n",
    "                    #pending_suggest_acts = list(filter((suggest_act).__ne__, pending_suggest_acts))\n",
    "                    act_list.append(new_act)\n",
    "                    row['act_list'] = act_list\n",
    "\n",
    "            else:\n",
    "                act = FreeAct(action=edit_act, agent=row['subject'])\n",
    "                act_list.append(act)\n",
    "                row['act_list'] = act_list\n",
    "                \n",
    "        pending_suggest_actlist.append(pending_suggest_acts)\n",
    "\n",
    "    df['pending_suggests'] = pending_suggest_actlist\n",
    "    return df\n",
    "\n",
    "\n",
    "# Try:\n",
    "task_index = 28 #10  # 8\n",
    "df = e_transcript_dfs[task_index]\n",
    "process_intents(df)\n",
    "df = process_suggests(df, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_intents = df['intents'].apply(len).sum()\n",
    "num_rejects = df['acts'].apply(lambda l: len([act for act in l if isinstance(act, RejectAct)])).sum()\n",
    "num_accepts = df['acts'].apply(lambda l: len([act for act in l if isinstance(act, AcceptAct)])).sum()\n",
    "num_edits = df['acts'].apply(lambda l: len([act for act in l if isinstance(act, PhysicalAct)])).sum()\n",
    "num_unmatcheds = df['acts'].apply(lambda l: len([act for act in l if isinstance(act, DeliberationAct)])).sum()\n",
    "num_intents, num_accepts, num_rejects, num_edits, len(df[df.verb.isin(['adds', 'removes'])]), num_unmatcheds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
