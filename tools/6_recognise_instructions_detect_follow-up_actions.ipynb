{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts verbalised instruction such as \"connect Mount Basel to Montreux\", and pairs them with the follow-up action that may *match* (e.g. if the other connects Basel to Montreux) or *mismatch* (e.g. if the other connects Basel to Neuchatel) with the instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "# from spacy.matcher import Matcher\n",
    "# from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "from read_utils import read_tables, read_network\n",
    "from act_utils import SuggestAct, PhysicalAct, \\\n",
    "    AcceptAct, RejectAct, FreeAct, \\\n",
    "    make_edit_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /home/utku/.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/utku/.local/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: thinc==7.4.1 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/utku/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (45.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.17.4)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ../processed_data/annotated_corpus\n"
     ]
    }
   ],
   "source": [
    "# Inputs.\n",
    "data_dir = pl.Path('../data')\n",
    "network_file = data_dir.joinpath('metadata/network.json')\n",
    "\n",
    "processed_data_dir = pl.Path('../processed_data')\n",
    "corpus_dir = processed_data_dir.joinpath('corpus')\n",
    "\n",
    "# # Outputs.\n",
    "annot_corpus_dir = processed_data_dir.joinpath('annotated_corpus')\n",
    "annot_corpus_pickle_file = annot_corpus_dir.joinpath(\n",
    "    'justhing19_annotated_corpus.pickle')\n",
    "\n",
    "for d in [annot_corpus_dir]:\n",
    "    if not d.exists():\n",
    "        d.mkdir()\n",
    "        print('Created {}'.format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus tables (logs with transcripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading transcript files from ../processed_data/corpus.\n",
      "transcript 10 files found.\n",
      "File justhink19_corpus_07 belongs to team  7\n",
      "File justhink19_corpus_08 belongs to team  8\n",
      "File justhink19_corpus_09 belongs to team  9\n",
      "File justhink19_corpus_10 belongs to team 10\n",
      "File justhink19_corpus_11 belongs to team 11\n",
      "File justhink19_corpus_17 belongs to team 17\n",
      "File justhink19_corpus_18 belongs to team 18\n",
      "File justhink19_corpus_20 belongs to team 20\n",
      "File justhink19_corpus_28 belongs to team 28\n",
      "File justhink19_corpus_47 belongs to team 47\n",
      "Transcript of  7 has 1059 utterances\n",
      "Transcript of  8 has  932 utterances\n",
      "Transcript of  9 has 1076 utterances\n",
      "Transcript of 10 has  769 utterances\n",
      "Transcript of 11 has  910 utterances\n",
      "Transcript of 17 has  451 utterances\n",
      "Transcript of 18 has  506 utterances\n",
      "Transcript of 20 has  653 utterances\n",
      "Transcript of 28 has  490 utterances\n",
      "Transcript of 47 has  642 utterances\n"
     ]
    }
   ],
   "source": [
    "corpus_dfs = read_tables(corpus_dir, form='transcript')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the background network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network read from : 10 nodes, 20 edges\n"
     ]
    }
   ],
   "source": [
    "network = read_network(network_file)\n",
    "print('Network read from {}: {} nodes, {} edges'.format(\n",
    "    network, network.number_of_nodes(), network.number_of_edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parsers and rulers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser for edge objects in the extended transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_edge_object(obj, names=False):\n",
    "    ''''Parses edit event object string to its node ids\n",
    "    e.g. Zurich-Gallen (2-8)' to [2, 8]'''\n",
    "    if names:  # Parse for names.\n",
    "        (u, v) = obj.split()[0].split('-')\n",
    "    else:  # Parse for node indices.\n",
    "        (u, v) = obj.split()[1].strip('(').strip(')').split('-')\n",
    "        u = int(u)\n",
    "        v = int(v)\n",
    "    return [u, v]\n",
    "\n",
    "\n",
    "# Try\n",
    "obj = 'Zurich-Gallen (2-8)'\n",
    "parse_edge_object(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keywords to detect instuction entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADD {'go', 'add', 'do', 'put', 'connect', 'build'}\n",
      "REMOVE {'rub', 'cut', 'erase', 'remove', 'away', 'delete'}\n"
     ]
    }
   ],
   "source": [
    "entity_keywords = {\n",
    "    'ADD': {\n",
    "        'add',    # \"adding zurich to bern .\"\n",
    "        'do',\n",
    "        'go',\n",
    "        'put',    # \"putting that one there\"\n",
    "        'connect',\n",
    "        'build',  # \"i'll build mount luzern to zermatt\"\n",
    "    },\n",
    "    'REMOVE': {\n",
    "        'remove',\n",
    "        \"delete\",  # \"okay so delete that .\"\n",
    "        'erase',\n",
    "        'cut',    # 'yeah then cut out mount basel to mount interlaken .'\n",
    "        'away',   # 'take away',\n",
    "        'rub',    # 'rub that out', #as in \"it's 3 francs rub that out\" ; \"no wait let me rub that out again .\" ; \"oh then rub that out\"\n",
    "    },\n",
    "}\n",
    "\n",
    "for k, words in entity_keywords.items():\n",
    "    print(k, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to recognise instructions from an utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ADD(9, None)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">to mount \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    davos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NODE</span>\n",
       "</mark>\n",
       " .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_ruler(network, entity_keywords):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "    ruler = EntityRuler(nlp)\n",
    "\n",
    "    node_ids = list()\n",
    "    node_patterns = list()\n",
    "    for u, d in network.nodes(data=True):\n",
    "        word = d['label'].split()[-1]\n",
    "        identifier = str(u)\n",
    "        pattern = {'id': identifier, 'label': 'NODE', \"pattern\": [\n",
    "            {'LOWER': word.lower()}]}\n",
    "        node_patterns.append(pattern)\n",
    "        node_ids.append(identifier)\n",
    "\n",
    "    entity_ids = list()\n",
    "    entity_patterns = list()\n",
    "    for label, words in entity_keywords.items():\n",
    "        for word in words:\n",
    "            identifier = str(label)  # [0]\n",
    "            pattern = {'id': identifier, 'label': label, \"pattern\": [\n",
    "                {'LOWER': word.lower()}]}\n",
    "            entity_patterns.append(pattern)\n",
    "            entity_ids.append(identifier)\n",
    "\n",
    "    patterns = [\n",
    "        *node_patterns,\n",
    "        *entity_patterns,\n",
    "    ]\n",
    "    ruler.add_patterns(patterns)\n",
    "    nlp.add_pipe(ruler)\n",
    "\n",
    "    return nlp, node_ids, entity_ids\n",
    "\n",
    "\n",
    "def get_node_ids(text, doc):\n",
    "    node_ids = [int(ent.ent_id_) for ent in doc.ents if ent.label_ == 'NODE']\n",
    "    return node_ids\n",
    "\n",
    "\n",
    "def recognise_instructions(text, node_ids, entity_ids, nlp,\n",
    "                           default_entity_id='ADD'):\n",
    "    '''Possible intended actions as entities.'''\n",
    "    doc = nlp(text)\n",
    "\n",
    "    instructions = list()\n",
    "    template = [None, [None, None]]  # an instruction template\n",
    "    for ent in doc.ents:\n",
    "        ent_id = ent.ent_id_\n",
    "\n",
    "        if ent_id in entity_ids:\n",
    "            if template[0] is None:\n",
    "                template[0] = ent_id\n",
    "            else:\n",
    "                template = [ent_id, [None, None]]\n",
    "\n",
    "        elif ent_id in node_ids:\n",
    "            if template[1][0] is None:\n",
    "                template[1][0] = ent_id\n",
    "            elif template[1][1] is None:\n",
    "                if ent_id != template[1][0]:\n",
    "                    template[1][1] = ent_id\n",
    "                # Start a new entity if has a verb.\n",
    "                # Default to add or the previous\n",
    "                if template[0] is None:\n",
    "                    if len(instructions) > 0:\n",
    "                        template[0] = instructions[-1].name\n",
    "                    else:\n",
    "                        template[0] = default_entity_id\n",
    "\n",
    "                instruction = make_edit_action(template[0], template[1])\n",
    "                if instruction is not None:\n",
    "                    instructions.append(instruction)\n",
    "                template = [None, [None, None]]\n",
    "\n",
    "    if template[1][0] is not None:\n",
    "        if template[0] is None:  # assume adds if otherwise detected\n",
    "            template[0] = 'ADD'\n",
    "        instruction = make_edit_action(template[0], template[1])\n",
    "        if instruction is not None:\n",
    "            instructions.append(instruction)\n",
    "\n",
    "    return instructions\n",
    "\n",
    "\n",
    "# Try\n",
    "text = \"go from basel to zurich and then from zurich to saint gallen .\"\n",
    "# text = \"then rub that out and then go , interlaken to mount bern .\"\n",
    "text = \"okay rub it out and go bern to interlaken .\"\n",
    "text = 'is that how much that ?'\n",
    "text = \"how do i get off this screen ?\"\n",
    "text = \"go from basel to zurich and then from zurich to saint gallen .\"\n",
    "text = 'to mount davos .'\n",
    "# text = \"then rub that out and then go , interlaken .\"\n",
    "nlp, node_ids, entity_ids = prepare_ruler(network, entity_keywords)\n",
    "\n",
    "\n",
    "entities = recognise_instructions(text, node_ids, entity_ids, nlp)\n",
    "display(entities)\n",
    "\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to process a row or a table to recognise instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_no</th>\n",
       "      <th>attempt_no</th>\n",
       "      <th>turn_no</th>\n",
       "      <th>utterance_no</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>nodes</th>\n",
       "      <th>instructions</th>\n",
       "      <th>acts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.296</td>\n",
       "      <td>R</td>\n",
       "      <td>shows</td>\n",
       "      <td>observe gesture</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>R</td>\n",
       "      <td>says</td>\n",
       "      <td>so, ann and bob, let's start building the trac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>33.409</td>\n",
       "      <td>33.409</td>\n",
       "      <td>A</td>\n",
       "      <td>presses</td>\n",
       "      <td>help (enabled)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.000</td>\n",
       "      <td>41.161</td>\n",
       "      <td>A</td>\n",
       "      <td>says</td>\n",
       "      <td>okay , so</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.580</td>\n",
       "      <td>45.036</td>\n",
       "      <td>B</td>\n",
       "      <td>says</td>\n",
       "      <td>so we have to connect all the places with trac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>669.659</td>\n",
       "      <td>669.659</td>\n",
       "      <td>A</td>\n",
       "      <td>presses</td>\n",
       "      <td>submit (enabled)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>669.736</td>\n",
       "      <td>669.736</td>\n",
       "      <td>T</td>\n",
       "      <td>submits</td>\n",
       "      <td>cost=22 (opt_cost=22)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>670.000</td>\n",
       "      <td>670.000</td>\n",
       "      <td>R</td>\n",
       "      <td>shows</td>\n",
       "      <td>happy emotion</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>670.001</td>\n",
       "      <td>670.001</td>\n",
       "      <td>R</td>\n",
       "      <td>shows</td>\n",
       "      <td>happy gesture</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>-1</td>\n",
       "      <td>670.087</td>\n",
       "      <td>670.087</td>\n",
       "      <td>R</td>\n",
       "      <td>says</td>\n",
       "      <td>congratulations! you found the best way to con...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team_no  attempt_no  turn_no  utterance_no    start      end subject  \\\n",
       "0         28           1        1            -1    0.296    0.296       R   \n",
       "1         28           1        1            -1    0.365    0.365       R   \n",
       "2         28           1        1            -1   33.409   33.409       A   \n",
       "3         28           1        1             0   40.000   41.161       A   \n",
       "4         28           1        1             1   40.580   45.036       B   \n",
       "..       ...         ...      ...           ...      ...      ...     ...   \n",
       "485       28           5       44            -1  669.659  669.659       A   \n",
       "486       28           5       44            -1  669.736  669.736       T   \n",
       "487       28           5       44            -1  670.000  670.000       R   \n",
       "488       28           5       44            -1  670.001  670.001       R   \n",
       "489       28           5       44            -1  670.087  670.087       R   \n",
       "\n",
       "        verb                                             object nodes  \\\n",
       "0      shows                                    observe gesture    []   \n",
       "1       says  so, ann and bob, let's start building the trac...    []   \n",
       "2    presses                                     help (enabled)    []   \n",
       "3       says                                          okay , so    []   \n",
       "4       says  so we have to connect all the places with trac...    []   \n",
       "..       ...                                                ...   ...   \n",
       "485  presses                                   submit (enabled)    []   \n",
       "486  submits                              cost=22 (opt_cost=22)    []   \n",
       "487    shows                                      happy emotion    []   \n",
       "488    shows                                      happy gesture    []   \n",
       "489     says  congratulations! you found the best way to con...    []   \n",
       "\n",
       "    instructions acts  \n",
       "0             []   []  \n",
       "1             []   []  \n",
       "2             []   []  \n",
       "3             []   []  \n",
       "4             []   []  \n",
       "..           ...  ...  \n",
       "485           []   []  \n",
       "486           []   []  \n",
       "487           []   []  \n",
       "488           []   []  \n",
       "489           []   []  \n",
       "\n",
       "[490 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recognise_instructions_for_row(sbj, verb, obj, nlp, node_ids, entity_ids):\n",
    "    '''make a suggest act or an edit act'''\n",
    "\n",
    "    # Make an node list and instruction list.\n",
    "    if verb == 'says' and sbj in ['A', 'B']:\n",
    "        text = obj\n",
    "        nodes = get_node_ids(text, nlp(text))\n",
    "        instructions = recognise_instructions(text, node_ids, entity_ids, nlp)\n",
    "        if instructions is None:\n",
    "            instructions = []\n",
    "    else:\n",
    "        nodes = []\n",
    "        instructions = []\n",
    "\n",
    "    # Make an act list.\n",
    "    acts = list()\n",
    "    for instruction in instructions:\n",
    "        act = SuggestAct(instruction, agent=sbj)\n",
    "        acts.append(act)\n",
    "\n",
    "    if verb == 'adds':\n",
    "        act_verb = 'ADD'\n",
    "    elif verb == 'removes':\n",
    "        act_verb = 'REMOVE'\n",
    "    else:\n",
    "        act_verb = None\n",
    "    if act_verb is not None:\n",
    "        action = make_edit_action(act_verb, parse_edge_object(obj))\n",
    "        act = PhysicalAct(action, sbj)\n",
    "        acts.append(act)\n",
    "\n",
    "    return nodes, instructions, acts\n",
    "\n",
    "\n",
    "def recognise_instructions_for_table(df, network, entity_keywords, inplace=False):\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    nlp, node_ids, entity_ids = prepare_ruler(network, entity_keywords)\n",
    "\n",
    "    node_lists, instruction_lists, act_lists = list(), list(), list()\n",
    "    for i, row in df.iterrows():\n",
    "        nodes, instructions, acts = recognise_instructions_for_row(\n",
    "            row['subject'], row['verb'], row['object'],\n",
    "            nlp, node_ids, entity_ids)\n",
    "\n",
    "        node_lists.append(nodes)\n",
    "        instruction_lists.append(instructions)\n",
    "        act_lists.append(acts)\n",
    "\n",
    "    df['nodes'] = node_lists\n",
    "    df['instructions'] = instruction_lists\n",
    "    df['acts'] = act_lists\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Try:\n",
    "team_no = 28  # 8\n",
    "df = corpus_dfs[team_no].copy()\n",
    "# df\n",
    "recognise_instructions_for_table(df, network, entity_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to match instructions and actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_no</th>\n",
       "      <th>attempt_no</th>\n",
       "      <th>turn_no</th>\n",
       "      <th>utterance_no</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>nodes</th>\n",
       "      <th>instructions</th>\n",
       "      <th>acts</th>\n",
       "      <th>pending_suggests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.296</td>\n",
       "      <td>R</td>\n",
       "      <td>shows</td>\n",
       "      <td>observe gesture</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>R</td>\n",
       "      <td>says</td>\n",
       "      <td>so, ann and bob, let's start building the trac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>33.409</td>\n",
       "      <td>33.409</td>\n",
       "      <td>A</td>\n",
       "      <td>presses</td>\n",
       "      <td>help (enabled)</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.000</td>\n",
       "      <td>41.161</td>\n",
       "      <td>A</td>\n",
       "      <td>says</td>\n",
       "      <td>okay , so</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.580</td>\n",
       "      <td>45.036</td>\n",
       "      <td>B</td>\n",
       "      <td>says</td>\n",
       "      <td>so we have to connect all the places with trac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_no  attempt_no  turn_no  utterance_no   start     end subject  \\\n",
       "0       28           1        1            -1   0.296   0.296       R   \n",
       "1       28           1        1            -1   0.365   0.365       R   \n",
       "2       28           1        1            -1  33.409  33.409       A   \n",
       "3       28           1        1             0  40.000  41.161       A   \n",
       "4       28           1        1             1  40.580  45.036       B   \n",
       "\n",
       "      verb                                             object nodes  \\\n",
       "0    shows                                    observe gesture    []   \n",
       "1     says  so, ann and bob, let's start building the trac...    []   \n",
       "2  presses                                     help (enabled)    []   \n",
       "3     says                                          okay , so    []   \n",
       "4     says  so we have to connect all the places with trac...    []   \n",
       "\n",
       "  instructions acts pending_suggests  \n",
       "0           []   []               []  \n",
       "1           []   []               []  \n",
       "2           []   []               []  \n",
       "3           []   []               []  \n",
       "4           []   []               []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 5 8 77 77 64\n"
     ]
    }
   ],
   "source": [
    "def match_instructions_and_actions(df, inplace=False, verbose=False):\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    pending_suggest_actlist = list()\n",
    "    pending_suggest_acts = list()\n",
    "    turn_no = 1\n",
    "    for i, row in df.iterrows():\n",
    "        pending_suggest_acts = list(pending_suggest_acts)\n",
    "        act_list = row['acts']\n",
    "        current_turn_no = row['turn_no']\n",
    "\n",
    "        # flush at every turn change\n",
    "        if current_turn_no != -1 and current_turn_no == turn_no + 1:\n",
    "            if verbose:\n",
    "                print('Cleared at {} at row {}'.format(current_turn_index, i))\n",
    "            pending_suggest_acts = list()\n",
    "            turn_no = current_turn_no\n",
    "\n",
    "\n",
    "        suggest_acts = [act for act in act_list if isinstance(act, SuggestAct)]\n",
    "        edit_acts = [act for act in act_list if isinstance(act, PhysicalAct)]\n",
    "        assert len(edit_acts) <= 1, 'more than one edit act? at {}'.format(row)\n",
    "\n",
    "        pending_suggest_acts = pending_suggest_acts + suggest_acts\n",
    "\n",
    "        if len(edit_acts) > 0:\n",
    "            edit_act = edit_acts[0]\n",
    "\n",
    "            if verbose and len(pending_suggest_acts) > 0:\n",
    "                print()\n",
    "                print('Matching {} to {}'.format(\n",
    "                    pending_suggest_acts, edit_acts))\n",
    "\n",
    "            # check with its only item in this trivial case\n",
    "            # get suggests by the other speaker.\n",
    "            others_acts = [\n",
    "                a for a in pending_suggest_acts if a.agent != row['subject']]\n",
    "            if len(others_acts) > 0:\n",
    "                new_act = None\n",
    "\n",
    "                for suggest_act in others_acts:\n",
    "                    if suggest_act.action.partial_equals(edit_act.action):\n",
    "                        new_act = AcceptAct(suggest_act, agent=edit_act.agent)\n",
    "                        if verbose:\n",
    "                            print('Matched {} to {}'.format(\n",
    "                                edit_act, suggest_act))\n",
    "\n",
    "                suggest_act = others_acts[-1]\n",
    "                if new_act is None:\n",
    "                    new_act = RejectAct(suggest_act, agent=edit_acts[0].agent)\n",
    "                    if verbose:\n",
    "                        print('No match {}: Create {}'.format(\n",
    "                            suggest_act, new_act))\n",
    "\n",
    "                if new_act is not None:\n",
    "                    # remove all that match suggest_act.\n",
    "                    l = list(pending_suggest_acts)\n",
    "                    for s in pending_suggest_acts:\n",
    "                        if s.action.partial_equals(suggest_act.action):\n",
    "                            l.remove(s)\n",
    "                    pending_suggest_acts = l\n",
    "                    #pending_suggest_acts = list(filter((suggest_act).__ne__, pending_suggest_acts))\n",
    "                    act_list.append(new_act)\n",
    "                    row['acts'] = act_list\n",
    "\n",
    "            else:\n",
    "                act = FreeAct(action=edit_act, agent=row['subject'])\n",
    "                act_list.append(act)\n",
    "                row['acts'] = act_list\n",
    "                \n",
    "        pending_suggest_actlist.append(pending_suggest_acts)\n",
    "\n",
    "    df['pending_suggests'] = pending_suggest_actlist\n",
    "    return df\n",
    "\n",
    "\n",
    "# Try.\n",
    "task_index = 28 #10  # 8\n",
    "df = corpus_dfs[task_index].copy()\n",
    "df = recognise_instructions_for_table(df, network, entity_keywords)\n",
    "df = match_instructions_and_actions(df)\n",
    "display(df.head())\n",
    "\n",
    "num_intents = df['instructions'].apply(len).sum()\n",
    "num_rejects = df['acts'].apply(lambda l: len(\n",
    "    [act for act in l if isinstance(act, RejectAct)])).sum()\n",
    "num_accepts = df['acts'].apply(lambda l: len(\n",
    "    [act for act in l if isinstance(act, AcceptAct)])).sum()\n",
    "num_edits = df['acts'].apply(lambda l: len(\n",
    "    [act for act in l if isinstance(act, PhysicalAct)])).sum()\n",
    "num_unmatcheds = df['acts'].apply(lambda l: len(\n",
    "    [act for act in l if isinstance(act, FreeAct)])).sum()\n",
    "\n",
    "c = len(df[df.verb.isin(['adds', 'removes'])])\n",
    "print(num_intents, num_accepts, num_rejects, num_edits, c, num_unmatcheds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['acts'].apply(lambda l: len(\n",
    "    [act for act in l if isinstance(act, AcceptAct)])).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate the corpus tables with instructions and follow-up actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing team  7 ...\n",
      "Processing team  8 ...\n",
      "Processing team  9 ...\n",
      "Processing team 10 ...\n",
      "Processing team 11 ...\n",
      "Processing team 17 ...\n",
      "Processing team 18 ...\n",
      "Processing team 20 ...\n",
      "Processing team 28 ...\n",
      "Processing team 47 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "annotated_dfs = dict()\n",
    "for team_no in sorted(corpus_dfs):\n",
    "    print('Processing team {:2d} ...'.format(team_no))\n",
    "    df = corpus_dfs[team_no].copy()\n",
    "\n",
    "    recognise_instructions_for_table(df, network, entity_keywords, inplace=True)\n",
    "    match_instructions_and_actions(df, inplace=True)\n",
    "    \n",
    "    annotated_dfs[team_no] = df\n",
    "          \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to csv files and a pickle file (to easily load acts etc. later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save team  7 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_07.csv\n",
      "Save team  8 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_08.csv\n",
      "Save team  9 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_09.csv\n",
      "Save team 10 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_10.csv\n",
      "Save team 11 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_11.csv\n",
      "Save team 17 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_17.csv\n",
      "Save team 18 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_18.csv\n",
      "Save team 20 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_20.csv\n",
      "Save team 28 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_28.csv\n",
      "Save team 47 to ../processed_data/annotated_corpus/justhink19_annotated_corpus_47.csv\n"
     ]
    }
   ],
   "source": [
    "for team_no in sorted(annotated_dfs):\n",
    "    # Make filename.\n",
    "    file = annot_corpus_dir.joinpath(\n",
    "        'justhink19_annotated_corpus_{:02d}.csv'.format(team_no))\n",
    "    print('Save team {:2d} to {}'.format(team_no, file))\n",
    "\n",
    "    # Export to file.\n",
    "    annotated_dfs[team_no].to_csv(file, sep='\\t',\n",
    "                                  float_format='%.3f', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to a pickle file (to easily load in another notebook, preserving data types e.g. acts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all teams to ../processed_data/annotated_corpus/justhing19_annotated_corpus.pickle\n"
     ]
    }
   ],
   "source": [
    "with annot_corpus_pickle_file.open('wb') as handle:\n",
    "    pickle.dump(annotated_dfs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('Saved all teams to {}'.format(annot_corpus_pickle_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
